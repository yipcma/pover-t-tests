{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desert Povery Lab: Measuring Poverty One Country at a time\n",
    "## Roadmap\n",
    "1. Download the data(once)\n",
    "2. Inspect the data for each country on train and test sets\n",
    "3. Impute missing values\n",
    "4. Test baseline model\n",
    "5. Perform cross validation and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool, cv, CatboostIpythonWidget\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "rdn = 42\n",
    "countries = ['A', 'B', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./input/submission_format.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download data (just once!)\n",
    "# import wget\n",
    "# url = 'https://s3.amazonaws.com/drivendata/data/50/public/'\n",
    "# levels = ['hhold', 'indiv']\n",
    "# types = ['train', 'test']\n",
    "# wget.download(url + 'submission_format.csv', './input/submission_format.csv')\n",
    "# [wget.download(f'{url}{x}_{y}_{z}.csv' , f'./input/{x}_{y}_{z}.csv') for x in countries for y in levels for z in types]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all data, separately! Because they all have different columns\n",
    "hhld_train = [pd.read_csv(f'./input/{x}_hhold_train.csv', index_col=['id']) for x in countries]\n",
    "hhld_test = [pd.read_csv(f'./input/{x}_hhold_test.csv', index_col=['id']) for x in countries]\n",
    "indiv_train = [pd.read_csv(f'./input/{x}_indiv_train.csv', index_col=['iid', 'id']) for x in countries]\n",
    "indiv_test = [pd.read_csv(f'./input/{x}_indiv_test.csv', index_col=['iid', 'id']) for x in countries]\n",
    "template = pd.read_csv('./input/submission_format.csv', index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 16784, 0]\n",
      "[False    4500\n",
      "True     3703\n",
      "Name: poor, dtype: int64, False    3004\n",
      "True      251\n",
      "Name: poor, dtype: int64, False    5496\n",
      "True      973\n",
      "Name: poor, dtype: int64]\n",
      "[          nEsgxvAq     OMtioXZZ     YFMZwKrU     TiwRslOh\n",
      "count  8203.000000  8203.000000  8203.000000  8203.000000\n",
      "mean     -7.590638    17.464464    -2.985615    -4.191028\n",
      "std       5.810942    10.853654     0.896245     4.472567\n",
      "min     -70.000000  -127.000000    -4.000000   -31.000000\n",
      "25%     -10.000000    12.000000    -4.000000    -7.000000\n",
      "50%      -4.000000    12.000000    -3.000000    -3.000000\n",
      "75%      -4.000000    21.000000    -2.000000    -1.000000\n",
      "max      -4.000000   111.000000     1.000000     3.000000,           wJthinfa     ZvEApWrk     vuQrLzvK    FGWqGkmD     qrOrXLPM  \\\n",
      "count  3255.000000  3255.000000  3255.000000  602.000000  3255.000000   \n",
      "mean     43.381260    96.040860    17.427343   -7.509967    22.203379   \n",
      "std      22.728441   105.556895    72.057949    9.499141     6.962658   \n",
      "min    -126.000000    -2.000000  -125.000000  -53.000000     8.000000   \n",
      "25%      26.000000    33.000000   -39.000000  -13.000000    16.000000   \n",
      "50%      42.000000    68.000000    27.000000   -8.000000    24.000000   \n",
      "75%      58.000000   138.000000    77.000000    2.000000    24.000000   \n",
      "max     122.000000  1069.000000   127.000000    2.000000    48.000000   \n",
      "\n",
      "          BXOWgPgL    umkFMfvA     McFBIGsm     NjDdhqIe     rCVqiShm  \\\n",
      "count  2504.000000  890.000000  2504.000000  3255.000000  3255.000000   \n",
      "mean    158.354633  -33.279775   301.106230    88.597849   -48.195392   \n",
      "std     124.535287    8.231694   155.904844   107.268927    52.981575   \n",
      "min     -40.000000  -63.000000   -43.000000    -7.000000  -968.000000   \n",
      "25%      50.000000  -36.000000   185.000000    28.000000   -48.000000   \n",
      "50%     150.000000  -36.000000   305.000000    63.000000   -28.000000   \n",
      "75%     250.000000  -27.000000   425.000000    98.000000   -28.000000   \n",
      "max     500.000000  -18.000000   605.000000  1253.000000    -8.000000   \n",
      "\n",
      "          ...         IrxBnWxE     BRzuVmyf      dnlnKrAg     VyHofjLM  \\\n",
      "count     ...       272.000000  1794.000000    532.000000  3255.000000   \n",
      "mean      ...         0.647059    45.675585 -15965.135338     1.974808   \n",
      "std       ...         9.097690    41.675286     39.715899     1.565015   \n",
      "min       ...       -61.000000     9.000000 -16047.000000    -2.000000   \n",
      "25%       ...         3.000000    21.000000 -15999.000000     2.000000   \n",
      "50%       ...         3.000000    36.000000 -15959.000000     2.000000   \n",
      "75%       ...         3.000000    51.000000 -15927.000000     2.000000   \n",
      "max       ...         3.000000   276.000000 -15911.000000     8.000000   \n",
      "\n",
      "          GrLBZowF     oszSdLhD    aAufyreG     cDhZjxaW     OSmfjCbE  \\\n",
      "count  3255.000000  3255.000000  909.000000  3255.000000  2504.000000   \n",
      "mean   -249.528111     0.670661   45.782178   -85.937020  -339.568291   \n",
      "std     322.468103     1.833827   49.499821   114.537914   147.833796   \n",
      "min   -5044.000000   -23.000000   -6.000000 -3639.000000  -506.000000   \n",
      "25%    -364.000000     1.000000   12.000000  -119.000000  -501.000000   \n",
      "50%    -184.000000     1.000000   39.000000   -59.000000  -356.000000   \n",
      "75%     -64.000000     1.000000   48.000000   -39.000000  -256.000000   \n",
      "max      -4.000000     1.000000  426.000000     1.000000    34.000000   \n",
      "\n",
      "          IOMvIGQS  \n",
      "count  3255.000000  \n",
      "mean     78.568356  \n",
      "std      63.123421  \n",
      "min       0.000000  \n",
      "25%      50.000000  \n",
      "50%      50.000000  \n",
      "75%     100.000000  \n",
      "max     900.000000  \n",
      "\n",
      "[8 rows x 23 columns],           LhUIIEHQ     PNAiwXUz     jmsRIiqp     NONtAKOM     kLAQgdly  \\\n",
      "count  6469.000000  6469.000000  6469.000000  6469.000000  6469.000000   \n",
      "mean      7.899366    22.646932    10.876179    -6.674911  -298.008966   \n",
      "std       1.482295    78.914475     9.164273    10.723440   286.793836   \n",
      "min       7.000000    -9.000000     1.000000  -100.000000 -4150.000000   \n",
      "25%       7.000000    -5.000000     1.000000   -10.000000  -430.000000   \n",
      "50%       7.000000    -1.000000     8.000000    -4.000000  -250.000000   \n",
      "75%       9.000000     7.000000    15.000000     2.000000   -10.000000   \n",
      "max      35.000000   711.000000    85.000000     8.000000   -10.000000   \n",
      "\n",
      "          WWuPOkor     CtFxPQPT     GIwNbAsH     qLDzvjiU     detlNNFh  \\\n",
      "count  6469.000000  6469.000000  6469.000000  6469.000000  6469.000000   \n",
      "mean      3.427887   -68.832586    -3.166950     0.315659     2.667337   \n",
      "std       2.999990   159.918843     6.366799     1.264827    28.862018   \n",
      "min     -20.000000 -1611.000000   -66.000000    -1.000000    -1.000000   \n",
      "25%       0.000000   -43.000000    -6.000000    -1.000000    -1.000000   \n",
      "50%       5.000000   -15.000000    -3.000000     0.000000    -1.000000   \n",
      "75%       5.000000    -8.000000     3.000000     1.000000    -1.000000   \n",
      "max       5.000000    -1.000000     3.000000    11.000000  1394.000000   \n",
      "\n",
      "          ...          kiAJBGqv     aFKPYcDt     gAZloxqF     phbxKGlB  \\\n",
      "count     ...       6469.000000  6469.000000  6469.000000  6469.000000   \n",
      "mean      ...         -0.375947    -6.743392  -157.758695  -292.249652   \n",
      "std       ...          3.084907     5.106988   258.817220   427.077633   \n",
      "min       ...         -4.000000    -9.000000 -2699.000000 -3602.000000   \n",
      "25%       ...         -3.000000    -9.000000  -179.000000  -425.000000   \n",
      "50%       ...         -1.000000    -9.000000   -39.000000   -83.000000   \n",
      "75%       ...          1.000000    -9.000000   -19.000000   -29.000000   \n",
      "max       ...         30.000000    39.000000     1.000000    -2.000000   \n",
      "\n",
      "          nTaJkLaJ     ZZGQNLOX     snkiwkvf     POJXrpmn     vSqQCatY  \\\n",
      "count  6469.000000  6469.000000  6469.000000  6469.000000  6469.000000   \n",
      "mean     79.976503   -19.349668  -173.290153     0.904004   112.213789   \n",
      "std     166.402429     5.017426   313.115779     2.415210   249.821599   \n",
      "min      -2.000000   -55.000000 -2410.000000   -18.000000    -5.000000   \n",
      "25%       5.000000   -19.000000  -160.000000     2.000000    -2.000000   \n",
      "50%      19.000000   -19.000000   -40.000000     2.000000     4.000000   \n",
      "75%      68.000000   -19.000000   -22.000000     2.000000    85.000000   \n",
      "max    1748.000000   -13.000000   -10.000000     2.000000  1495.000000   \n",
      "\n",
      "          mmoCpqWS  \n",
      "count  6469.000000  \n",
      "mean     12.788994  \n",
      "std      58.638214  \n",
      "min    -126.000000  \n",
      "25%      -6.000000  \n",
      "50%       1.000000  \n",
      "75%      52.000000  \n",
      "max     127.000000  \n",
      "\n",
      "[8 rows x 30 columns]]\n",
      "[31, 64, 85]\n"
     ]
    }
   ],
   "source": [
    "# EDA for the train and test data\n",
    "## Check for missing values\n",
    "print([x.isnull().sum().sum() for x in hhld_train])\n",
    "# print([x.isnull().sum().sum() for x in hhld_test])\n",
    "\n",
    "## inspect poverty distribution\n",
    "print([x.poor.value_counts() for x in hhld_train])\n",
    "\n",
    "## inspect integers and range\n",
    "print([ x.describe() for x in hhld_train])\n",
    "\n",
    "## inspect number of categories (min and max)\n",
    "print([np.max(x.iloc[:, np.where(x.dtypes == np.object)[0]].nunique()) for x in hhld_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3255 entries, 57071 to 4923\n",
      "Data columns (total 9 columns):\n",
      "FGWqGkmD    602 non-null float64\n",
      "BXOWgPgL    2504 non-null float64\n",
      "umkFMfvA    890 non-null float64\n",
      "McFBIGsm    2504 non-null float64\n",
      "IrxBnWxE    272 non-null float64\n",
      "BRzuVmyf    1794 non-null float64\n",
      "dnlnKrAg    532 non-null float64\n",
      "aAufyreG    909 non-null float64\n",
      "OSmfjCbE    2504 non-null float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 254.3 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1604 entries, 9135 to 52739\n",
      "Data columns (total 9 columns):\n",
      "FGWqGkmD    317 non-null float64\n",
      "BXOWgPgL    1243 non-null float64\n",
      "umkFMfvA    441 non-null float64\n",
      "McFBIGsm    1243 non-null float64\n",
      "IrxBnWxE    139 non-null float64\n",
      "BRzuVmyf    881 non-null float64\n",
      "dnlnKrAg    244 non-null float64\n",
      "aAufyreG    428 non-null float64\n",
      "OSmfjCbE    1245 non-null float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 125.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_b_na = hhld_train[1][hhld_train[1].columns[hhld_train[1].isnull().any()]]\n",
    "print(train_b_na.info())\n",
    "test_b_na = hhld_test[1][hhld_test[1].columns[hhld_test[1].isnull().any()]]\n",
    "print(test_b_na.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing values in country B concentrate on 9 numeric columns. To deal with the NaNs, try following strategies:\n",
    "1. drop columns with NA\n",
    "2. set extreme value -99999\n",
    "3. impute central tendency (mean, median, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cv(name, train, n):\n",
    "    # TODO: scale numerics, drop single level columns, impute missing\n",
    "    X = train.drop(['poor', 'country'], axis=1)\n",
    "    y = train.poor\n",
    "    cat_ind = np.where(np.logical_and(X.dtypes != np.float, X.dtypes != np.int))[0]\n",
    "    pool = Pool(X.values, y.values, cat_features=cat_ind)\n",
    "    model = CatBoostClassifier(train_dir=f'models/{name}/', task_type='GPU', name=name, iterations=n, loss_function='Logloss', random_seed=rdn)\n",
    "    scores = cv(pool, model.get_params(), stratified=True, seed=rdn, logging_level='Verbose')\n",
    "    return scores\n",
    "\n",
    "def model_train(name, train, n):\n",
    "    X = train.drop(['poor', 'country'], axis=1)\n",
    "    y = train.poor\n",
    "    cat_ind = np.where(np.logical_and(X.dtypes != np.float, X.dtypes != np.int))[0]\n",
    "    model = CatBoostClassifier(train_dir=f'models/{name}/', task_type='GPU', name=name, iterations=n, loss_function='Logloss', random_seed=rdn)\n",
    "    model.fit(X, y, cat_features=cat_ind, verbose=True)\n",
    "    return model\n",
    "\n",
    "def pred_make(model, X_test, country):\n",
    "    df = pd.DataFrame()\n",
    "    df['id'] = X_test.index.get_level_values('id')\n",
    "    df['country'] = country\n",
    "    df['poor'] = model.predict_proba(X_test.drop('country', axis=1))[:,1]\n",
    "    return df\n",
    "\n",
    "def mean_logloss(scores_a, scores_b, scores_c):\n",
    "    return np.average([np.min(scores_a['Logloss_test_avg']), np.min(scores_b['Logloss_test_avg']), np.min(scores_c['Logloss_test_avg'])], weights= np.array([x.country.shape[0] for x in hhld_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean train_b and examine effects\n",
    "## try 1: by dropna(axis=1)\n",
    "scores_b = make_cv('hhld_dropna_b', hhld_train[1].dropna(axis=1), 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_a = make_cv('hhld_a', hhld_train[0], 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_c = make_cv('hhld_c', hhld_train[2], 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_a.keys()\n",
    "np.argmin(scores_b['Logloss_test_avg'])\n",
    "\n",
    "# model_a = model_train('hhld_a', hhld_train[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train\n",
    "model_b = model_train('hhld_dropna_b', hhld_train[1].dropna(axis=1), np.argmin(scores_b['Logloss_test_avg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = model_train('hhld_a', hhld_train[0], np.argmin(scores_a['Logloss_test_avg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c = model_train('hhld_c', hhld_train[2], np.argmin(scores_c['Logloss_test_avg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and submit\n",
    "submission = pd.concat([pred_make(x, y.dropna(axis=1), z) for x, y, z in zip([model_a, model_b, model_c], hhld_test, countries)], axis=0)\n",
    "submission.to_csv('output/submission_b_dropna.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17004743833106328"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate score from cv\n",
    "mean_logloss(scores_a, scores_b, scores_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporate indiv data to hhld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6268, 461273, 0]\n",
      "[True     19684\n",
      "False    17876\n",
      "Name: poor, dtype: int64, False    18375\n",
      "True      1877\n",
      "Name: poor, dtype: int64, False    22868\n",
      "True      7045\n",
      "Name: poor, dtype: int64]\n",
      "[           OdXpbPGJ      ukWqmeSS\n",
      "count  31292.000000  37560.000000\n",
      "mean       8.719129    107.022764\n",
      "std       21.089956     91.795117\n",
      "min        4.000000      1.000000\n",
      "25%        4.000000     36.000000\n",
      "50%        4.000000     81.000000\n",
      "75%        4.000000    151.000000\n",
      "max      214.000000    551.000000,           BoxViLPz     qlLzyqpP     unRAgFtX      TJGiunYp    WmKLEUcd  \\\n",
      "count  5459.000000  1185.000000  1652.000000  12454.000000  354.000000   \n",
      "mean    -34.296025   -38.275949   -87.351090      0.629758    1.161017   \n",
      "std      18.357318    30.277305    89.976221      1.801028    3.992848   \n",
      "min     -68.000000  -177.000000  -644.000000     -1.000000  -19.000000   \n",
      "25%     -50.000000   -51.000000  -122.000000      0.000000   -1.000000   \n",
      "50%     -32.000000   -33.000000   -50.000000      0.000000    2.000000   \n",
      "75%     -20.000000    -9.000000   -23.000000      1.000000    5.000000   \n",
      "max      -8.000000    -9.000000    -5.000000     16.000000    5.000000   \n",
      "\n",
      "         DYgxQeEi    jfsTwowc      MGfpfHam     esHWAAyG    DtcKwIEv  \\\n",
      "count   48.000000  136.000000    438.000000  12804.00000  993.000000   \n",
      "mean  -140.145833   58.367647 -20053.849315     -8.52757    7.221551   \n",
      "std    166.546778   50.378392     14.162513      9.36105    1.687615   \n",
      "min   -800.000000    0.000000 -20067.000000   -148.00000   -6.000000   \n",
      "25%   -174.500000   18.000000 -20067.000000     -8.00000    7.000000   \n",
      "50%    -95.000000   45.000000 -20057.000000     -8.00000    8.000000   \n",
      "75%    -34.250000  108.000000 -20047.000000     -1.00000    8.000000   \n",
      "max      0.000000  324.000000 -19897.000000     -1.00000    8.000000   \n",
      "\n",
      "          ...         AJgudnHB      iZhWxnWa     fyfDnyQk      wJthinfa  \\\n",
      "count     ...        21.000000   2142.000000  1652.000000  20252.000000   \n",
      "mean      ...        32.142857 -15965.735761     0.328692      0.452400   \n",
      "std       ...        85.752572   1962.376212    10.110190      3.025749   \n",
      "min       ...         4.000000 -80001.000000   -51.000000     -6.000000   \n",
      "25%       ...         7.000000 -16001.000000     4.000000     -2.000000   \n",
      "50%       ...         9.000000 -15945.000000     4.000000      0.000000   \n",
      "75%       ...        18.000000 -15849.000000     4.000000      2.000000   \n",
      "max       ...       403.000000 -15369.000000     4.000000     14.000000   \n",
      "\n",
      "           nxAFXxLQ      mAeaImix    HZqPmvkr      ulQCDoYe     tzYvQeOb  \\\n",
      "count    361.000000  16524.000000  438.000000  20252.000000  2025.000000   \n",
      "mean    1148.722992     -8.763738   21.547945    -21.382579  -680.751605   \n",
      "std     2258.035086      3.230701   17.392132     67.795927   189.030118   \n",
      "min      152.000000    -28.000000   -4.000000   -127.000000  -810.000000   \n",
      "25%      602.000000     -8.000000    8.000000    -77.000000  -810.000000   \n",
      "50%      902.000000     -8.000000   20.000000    -32.000000  -810.000000   \n",
      "75%     1202.000000     -8.000000   32.000000     19.000000  -570.000000   \n",
      "max    29999.000000     -8.000000   62.000000    125.000000   -10.000000   \n",
      "\n",
      "          NfpXxGQk  \n",
      "count  3804.000000  \n",
      "mean  -7942.520505  \n",
      "std      70.342966  \n",
      "min   -8023.000000  \n",
      "25%   -7995.000000  \n",
      "50%   -7963.000000  \n",
      "75%   -7911.000000  \n",
      "max   -7675.000000  \n",
      "\n",
      "[8 rows x 32 columns],            XKQWlRjk      vWNISgEA      bsMfXBld      XKyOwsRR      CgAkQtOd\n",
      "count  29913.000000  29913.000000  29913.000000  29913.000000  29913.000000\n",
      "mean       1.481831     22.294788      5.317193    196.691372    -14.949217\n",
      "std       48.992077     31.615398      9.158482    280.885137     20.333932\n",
      "min     -128.000000      9.000000    -69.000000     -3.000000   -325.367200\n",
      "25%        1.000000      9.000000      9.000000     -3.000000     -7.000000\n",
      "50%        1.000000      9.000000      9.000000     -3.000000     -7.000000\n",
      "75%        1.000000      9.000000      9.000000    381.000000     -7.000000\n",
      "max      125.000000    149.000000      9.000000    949.000000     -7.000000]\n",
      "[25, 97, 62]\n"
     ]
    }
   ],
   "source": [
    "## Check for missing values in indiv data\n",
    "print([x.isnull().sum().sum() for x in indiv_train])\n",
    "# print([x.isnull().sum().sum() for x in hhld_test])\n",
    "\n",
    "## inspect poverty distribution\n",
    "print([x.poor.value_counts() for x in indiv_train])\n",
    "\n",
    "## inspect integers and range\n",
    "print([ x.describe() for x in indiv_train])\n",
    "\n",
    "## inspect number of categories (min and max)\n",
    "print([np.max(x.iloc[:, np.where(x.dtypes == np.object)[0]].nunique()) for x in indiv_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 28, 0]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect NaN in indiv (train and test same columns of missing data)\n",
    "[x.isnull().any().sum() for x in indiv_train]\n",
    "# [x.isnull().any().sum() for x in indiv_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeUgMnzF</th>\n",
       "      <th>CaukPfUC</th>\n",
       "      <th>MzEtIdUF</th>\n",
       "      <th>gtnNTNam</th>\n",
       "      <th>SWoXNmPc</th>\n",
       "      <th>eXbOkwhI</th>\n",
       "      <th>XONDGWjH</th>\n",
       "      <th>KsFoQcUV</th>\n",
       "      <th>qYRZCuJD</th>\n",
       "      <th>FPQrjGnS</th>\n",
       "      <th>...</th>\n",
       "      <th>XBldkztv</th>\n",
       "      <th>tbgZsPXD</th>\n",
       "      <th>qqVibbSA</th>\n",
       "      <th>MgCoFhXK</th>\n",
       "      <th>rFpoTXAq</th>\n",
       "      <th>RXcLsVAQ</th>\n",
       "      <th>rQWIpTiG</th>\n",
       "      <th>XizJGmbu</th>\n",
       "      <th>xqUooaNJ</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XJsPz</td>\n",
       "      <td>mOlYV</td>\n",
       "      <td>UFoKR</td>\n",
       "      <td>HIvIU</td>\n",
       "      <td>onRNG</td>\n",
       "      <td>YXCNt</td>\n",
       "      <td>ccbZA</td>\n",
       "      <td>kpkiH</td>\n",
       "      <td>fohru</td>\n",
       "      <td>scxJu</td>\n",
       "      <td>...</td>\n",
       "      <td>tbsMf</td>\n",
       "      <td>yOwsR</td>\n",
       "      <td>QQdHS</td>\n",
       "      <td>uEstx</td>\n",
       "      <td>Hikoa</td>\n",
       "      <td>zQvdC</td>\n",
       "      <td>xUYIC</td>\n",
       "      <td>juMSt</td>\n",
       "      <td>JTCKs</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XJsPz</td>\n",
       "      <td>mOlYV</td>\n",
       "      <td>axSTs</td>\n",
       "      <td>CXizI</td>\n",
       "      <td>onRNG</td>\n",
       "      <td>YXCNt</td>\n",
       "      <td>ccbZA</td>\n",
       "      <td>HgfUG</td>\n",
       "      <td>fohru</td>\n",
       "      <td>scxJu</td>\n",
       "      <td>...</td>\n",
       "      <td>XQevi</td>\n",
       "      <td>yOwsR</td>\n",
       "      <td>QQdHS</td>\n",
       "      <td>uEstx</td>\n",
       "      <td>Hikoa</td>\n",
       "      <td>zQvdC</td>\n",
       "      <td>xUYIC</td>\n",
       "      <td>juMSt</td>\n",
       "      <td>JTCKs</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XJsPz</td>\n",
       "      <td>kzSFB</td>\n",
       "      <td>axSTs</td>\n",
       "      <td>CXizI</td>\n",
       "      <td>onRNG</td>\n",
       "      <td>YXCNt</td>\n",
       "      <td>fOUHD</td>\n",
       "      <td>HgfUG</td>\n",
       "      <td>fohru</td>\n",
       "      <td>HRGCq</td>\n",
       "      <td>...</td>\n",
       "      <td>XQevi</td>\n",
       "      <td>yOwsR</td>\n",
       "      <td>QQdHS</td>\n",
       "      <td>gCSRj</td>\n",
       "      <td>Hikoa</td>\n",
       "      <td>zQvdC</td>\n",
       "      <td>rkLqZ</td>\n",
       "      <td>juMSt</td>\n",
       "      <td>JTCKs</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XJsPz</td>\n",
       "      <td>mOlYV</td>\n",
       "      <td>axSTs</td>\n",
       "      <td>CXizI</td>\n",
       "      <td>onRNG</td>\n",
       "      <td>YXCNt</td>\n",
       "      <td>fOUHD</td>\n",
       "      <td>HgfUG</td>\n",
       "      <td>fohru</td>\n",
       "      <td>scxJu</td>\n",
       "      <td>...</td>\n",
       "      <td>tbsMf</td>\n",
       "      <td>yOwsR</td>\n",
       "      <td>QQdHS</td>\n",
       "      <td>uEstx</td>\n",
       "      <td>Hikoa</td>\n",
       "      <td>zQvdC</td>\n",
       "      <td>rkLqZ</td>\n",
       "      <td>juMSt</td>\n",
       "      <td>JTCKs</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>XJsPz</td>\n",
       "      <td>mOlYV</td>\n",
       "      <td>axSTs</td>\n",
       "      <td>CXizI</td>\n",
       "      <td>onRNG</td>\n",
       "      <td>YXCNt</td>\n",
       "      <td>fOUHD</td>\n",
       "      <td>HgfUG</td>\n",
       "      <td>fohru</td>\n",
       "      <td>scxJu</td>\n",
       "      <td>...</td>\n",
       "      <td>tbsMf</td>\n",
       "      <td>yOwsR</td>\n",
       "      <td>QQdHS</td>\n",
       "      <td>uEstx</td>\n",
       "      <td>Hikoa</td>\n",
       "      <td>zQvdC</td>\n",
       "      <td>rkLqZ</td>\n",
       "      <td>FUUXv</td>\n",
       "      <td>JTCKs</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HeUgMnzF CaukPfUC MzEtIdUF gtnNTNam SWoXNmPc eXbOkwhI XONDGWjH KsFoQcUV  \\\n",
       "id                                                                           \n",
       "14    XJsPz    mOlYV    UFoKR    HIvIU    onRNG    YXCNt    ccbZA    kpkiH   \n",
       "18    XJsPz    mOlYV    axSTs    CXizI    onRNG    YXCNt    ccbZA    HgfUG   \n",
       "36    XJsPz    kzSFB    axSTs    CXizI    onRNG    YXCNt    fOUHD    HgfUG   \n",
       "39    XJsPz    mOlYV    axSTs    CXizI    onRNG    YXCNt    fOUHD    HgfUG   \n",
       "58    XJsPz    mOlYV    axSTs    CXizI    onRNG    YXCNt    fOUHD    HgfUG   \n",
       "\n",
       "   qYRZCuJD FPQrjGnS   ...   XBldkztv tbgZsPXD qqVibbSA MgCoFhXK rFpoTXAq  \\\n",
       "id                     ...                                                  \n",
       "14    fohru    scxJu   ...      tbsMf    yOwsR    QQdHS    uEstx    Hikoa   \n",
       "18    fohru    scxJu   ...      XQevi    yOwsR    QQdHS    uEstx    Hikoa   \n",
       "36    fohru    HRGCq   ...      XQevi    yOwsR    QQdHS    gCSRj    Hikoa   \n",
       "39    fohru    scxJu   ...      tbsMf    yOwsR    QQdHS    uEstx    Hikoa   \n",
       "58    fohru    scxJu   ...      tbsMf    yOwsR    QQdHS    uEstx    Hikoa   \n",
       "\n",
       "   RXcLsVAQ rQWIpTiG XizJGmbu xqUooaNJ country  \n",
       "id                                              \n",
       "14    zQvdC    xUYIC    juMSt    JTCKs       A  \n",
       "18    zQvdC    xUYIC    juMSt    JTCKs       A  \n",
       "36    zQvdC    rkLqZ    juMSt    JTCKs       A  \n",
       "39    zQvdC    rkLqZ    juMSt    JTCKs       A  \n",
       "58    zQvdC    rkLqZ    FUUXv    JTCKs       A  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG: leftjoin indiv to hhld on train A\n",
    "# indiv_train[0].head()\n",
    "# pd.Series(['A', 'A', 'B', 'C', 'C']).value_counts().index[0]\n",
    "indiv_a_mean = indiv_train[0].loc[:,indiv_train[0].dtypes == np.object].groupby('id').agg(lambda x: x.value_counts().index[0])\n",
    "indiv_a_mean.head()\n",
    "# train_a_concat = pd.concat([hhld_train[0], indiv_a_mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_train_dropna = [x.dropna(axis=1).drop(['poor', 'country'], axis=1) for x in indiv_train]\n",
    "indiv_train_reduced = [pd.concat([x.loc[:, x.dtypes == np.object].groupby('id').agg(lambda x: x.value_counts().index[0]), x.loc[:, x.dtypes != np.object].groupby('id').agg('mean')], axis=1) for x in indiv_train_dropna]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_test_dropna = [x.dropna(axis=1).drop(['country'], axis=1) for x in indiv_test]\n",
    "indiv_test_reduced = [pd.concat([x.loc[:, x.dtypes == np.object].groupby('id').agg(lambda x: x.value_counts().index[0]), x.loc[:, x.dtypes != np.object].groupby('id').agg('mean')], axis=1) for x in indiv_test_dropna]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train = [pd.concat([x.dropna(axis=1), y], axis=1) for x, y in zip(hhld_train, indiv_train_reduced)]\n",
    "combined_test = [pd.concat([x.dropna(axis=1), y], axis=1) for x, y in zip(hhld_test, indiv_test_reduced)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 0]\n",
      "[0, 0, 0]\n",
      "[0, 9, 0]\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# indiv_train_reduced[0].head()\n",
    "# hhld_train[0].head()\n",
    "# combined_train[0].head()\n",
    "print([x.isnull().any().sum() for x in hhld_train])\n",
    "print([x.isnull().any().sum() for x in combined_train])\n",
    "print([x.isnull().any().sum() for x in hhld_test])\n",
    "print([x.isnull().any().sum() for x in combined_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cvs = [make_cv(x, y, z) for x, y, z in zip(['combined_a', 'combined_b', 'combined_c'], combined_train, [2000, 600, 500])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_models = [model_train(x, y, np.argmin(z['Logloss_test_avg'])) for x, y, z in zip(['combined_a', 'combined_b', 'combined_c'], combined_train, combined_cvs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_combined = pd.concat([pred_make(x, y, z) for x, y, z in zip(combined_models, combined_test, countries)], axis=0).set_index('id').reindex(template.index)\n",
    "submission_combined.to_csv('output/submission_combined_dropna.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1713750497289378"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_logloss(*combined_cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna flow for combined data\n",
    "indiv_train_reduced = [pd.concat([x.loc[:, x.dtypes == np.object].groupby('id').agg(lambda x: x.value_counts().index[0]), x.loc[:, x.dtypes != np.object].groupby('id').agg('median')], axis=1) for x in [x.fillna(-99999).drop(['poor', 'country'], axis=1) for x in indiv_train]]\n",
    "indiv_test_reduced = [pd.concat([x.loc[:, x.dtypes == np.object].groupby('id').agg(lambda x: x.value_counts().index[0]), x.loc[:, x.dtypes != np.object].groupby('id').agg('median')], axis=1) for x in [x.fillna(-99999).drop(['country'], axis=1) for x in indiv_test]]\n",
    "combined_train = [pd.concat([x.fillna(-99999), y], axis=1) for x, y in zip(hhld_train, indiv_train_reduced)]\n",
    "combined_test = [pd.concat([x.fillna(-99999), y], axis=1) for x, y in zip(hhld_test, indiv_test_reduced)]\n",
    "combined_models = [model_train(x, y, np.argmin(z['Logloss_test_avg'])) for x, y, z in zip(['combined_a_fillna', 'combined_b_fillna', 'combined_c_fillna'], combined_train, combined_cvs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_combined = pd.concat([pred_make(x, y, z) for x, y, z in zip(combined_models, combined_test, countries)], axis=0).set_index('id').reindex(template.index)\n",
    "submission_combined.to_csv('output/submission_combined_fillna_med.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cvs = [make_cv(x, y, z) for x, y, z in zip(['combined_a_fillna', 'combined_fillna', 'combined_fillna'], combined_train, [2000, 600, 500])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17273918684293196"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_logloss(*combined_cvs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
